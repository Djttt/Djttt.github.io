{"summary":"<p>Self-supervised learning(SSL)允许模型使用给定的没有标注的数据集自动的去学习一个“good”的表征空间，Specifically, 如果我们的数据集是一堆图片，self-supervised learning 去学习一个模型来生成 “good” representation vector.</p>\n<span id=\"more\"></span>\n\n<h1 id=\"自监督学习-Self-Supervised-Learning\"><a href=\"#自监督学习-Self-Supervised-Learning\" class=\"headerlink\" title=\"自监督学习(Self-Supervised Learning)\"></a>自监督学习(Self-Supervised Learning)</h1><h2 id=\"什么是Self-Supervised-learning\"><a href=\"#什么是Self-Supervised-learning\" class=\"headerlink\" title=\"什么是Self-Supervised learning?\"></a>什么是Self-Supervised learning?</h2><p>现代机器学习(ML)需要大量带有便签的训练数据，但是通常获得大量人工标注的数据（human-labeled）是非常有挑战性的或者是非常昂贵的. 所以能否有一种方式能让我们要求机器去自动学习一个模型，这个模型能生成(generate good visual representations)好的视觉表征而不需要一个带有标签的数据集吗？ 自监督学习就是一种很好的方式！</p>\n<p>Self-supervised learning(SSL)允许模型使用给定的没有标注的数据集自动的去学习一个“good”的表征空间，Specifically, 如果我们的数据集是一堆图片，self-supervised learning 去学习一个模型来生成 “good” representation vector 对于图片来说。  </p>\n<p>之所以SSL这种方法在最近非常火，是因为这种在一种数据集学习到的模型通常也能在其他数据集上表现的很好，而这里的其他数据集往往是模型没有训练过或者见过的！</p>\n<h2 id=\"什么是一个好的表征-good-representation\"><a href=\"#什么是一个好的表征-good-representation\" class=\"headerlink\" title=\"什么是一个好的表征(good representation)\"></a>什么是一个好的表征(good representation)</h2><p>“好的”表示向量需要捕捉图像与数据集其余部分相关的重要特征。这意味着，数据集中表示语义相似实体的图像应该具有相似的表示向量，而数据集中的不同图像应该具有不同的表示向量。例如，苹果的两幅图像应该具有相似的表示向量，而苹果的图像和香蕉的图像应该具有不同的表示向量。</p>\n<h2 id=\"Contrastive-Learning-SimCLR\"><a href=\"#Contrastive-Learning-SimCLR\" class=\"headerlink\" title=\"Contrastive Learning: SimCLR\"></a>Contrastive Learning: SimCLR</h2><p><a href=\"https://arxiv.org/pdf/2002.05709.pdf\">SimCLR</a> 引入了一种新的架构，它使用 <strong>contrastive learning</strong> 来学习良好的视觉表示。对比学习旨在为相似的图像学习相似的表示，为不同的图像学习不同的表示。这个简单的想法让我们无需使用任何标签就能训练出一个出奇好的模型。</p>\n<p>具体来说，对于数据集中的每个图像，SimCLR 都会生成该图像的两个不同增强视图，称为<strong>positive pair</strong>。然后，鼓励模型为这对图像生成类似的表示向量。请参阅下面的架构说明（论文中的图 2）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> IPython.display <span class=\"keyword\">import</span> Image</span><br><span class=\"line\">Image(<span class=\"string\">&#x27;images/simclr_fig2.png&#x27;</span>, width=<span class=\"number\">500</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2024/10/20/deep-learning-optimizer-2/r_fig2.png\"></p>\n<p>给定一个图像 <strong>x</strong>，SimCLR 使用两种不同的数据增强方案 <strong>t</strong> 和 <strong>t’</strong> 来生成正图像对 <strong>$\\tilde{x}_i$</strong> 和 **$\\tilde{x}_j$**。$f$ 是一个基本的编码器网络，它从增强的数据样本中提取表示向量，分别产生 <strong>$h_i$</strong> 和 **$h_j$**。最后，一个小的神经网络投影头 $g$ 将表示向量映射到应用对比损失的空间。对比损失的目标是最大化最终向量 <strong>$z_i &#x3D; g(h_i)$</strong> 和 <strong>$z_j &#x3D; g(h_j)$</strong> 之间的一致性。我们稍后将更详细地讨论对比损失，您将可以实现它。<br>训练完成后，我们丢弃投影头 $g$，仅使用 $f$ 和表示 $h$ 来执行下游任务，例如分类。</p>\n<h2 id=\"数据增强-Data-Augmentation\"><a href=\"#数据增强-Data-Augmentation\" class=\"headerlink\" title=\"数据增强(Data Augmentation)\"></a>数据增强(Data Augmentation)</h2><ul>\n<li>随机调整大小并裁剪为 32x32。(Random resize and crop to 32x32)</li>\n<li>以0.5的概率水平翻转图像(Horizontally flip the image)</li>\n<li>0.8的概率(probability)应用color jitter(包含饱和度，对比度等)</li>\n<li>0.2的概率将image convert to grayscale(灰度图)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.datasets <span class=\"keyword\">import</span> CIFAR10</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">test_data_augmentation</span>(<span class=\"params\">correct_output=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    train_transform = compute_train_transform(seed=<span class=\"number\">2147483647</span>)</span><br><span class=\"line\">    trainset = torchvision.datasets.CIFAR10(root=<span class=\"string\">&#x27;./data&#x27;</span>, train=<span class=\"literal\">True</span>, download=<span class=\"literal\">True</span>, transform=train_transform)</span><br><span class=\"line\">    trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class=\"number\">2</span>, shuffle=<span class=\"literal\">False</span>, num_workers=<span class=\"number\">2</span>)</span><br><span class=\"line\">    dataiter = <span class=\"built_in\">iter</span>(trainloader)</span><br><span class=\"line\">    images, labels = <span class=\"built_in\">next</span>(dataiter)</span><br><span class=\"line\">    img = torchvision.utils.make_grid(images)</span><br><span class=\"line\">    img = img / <span class=\"number\">2</span> + <span class=\"number\">0.5</span>     <span class=\"comment\"># unnormalize</span></span><br><span class=\"line\">    npimg = img.numpy()</span><br><span class=\"line\">    plt.imshow(np.transpose(npimg, (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    output = images</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Maximum error in data augmentation: %g&quot;</span>%rel_error(output.numpy(), correct_output.numpy()))</span><br><span class=\"line\">test_data_augmentation(answers[<span class=\"string\">&#x27;data_augmentation&#x27;</span>])</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2024/10/20/deep-learning-optimizer-2/_augmentation.png\"></p>\n<h1 id=\"Base-Encoder-and-Projection-Head\"><a href=\"#Base-Encoder-and-Projection-Head\" class=\"headerlink\" title=\"Base Encoder and Projection Head\"></a>Base Encoder and Projection Head</h1><p>接下来的步骤是将基础编码器和投影头应用于增强样本 <strong>$\\tilde{x}_i$</strong> 和 **$\\tilde{x}_j$**。</p>\n<p>基础编码器 $f$ 提取增强样本的表示向量。SimCLR 论文发现使用更深更宽的模型可以提高性能，因此选择 <a href=\"https://arxiv.org/pdf/1512.03385.pdf\">ResNet</a> 作为基础编码器。基础编码器的输出是表示向量 <strong>$h_i &#x3D; f(\\tilde{x}_i$)</strong> 和 **$h_j &#x3D; f(\\tilde{x}_j$)**。</p>\n<p>投影头 $g$ 是一个小型神经网络，它将表示向量 <strong>$h_i$</strong> 和 <strong>$h_j$</strong> 映射到应用对比损失的空间。论文发现使用非线性投影头可以提高其前一层的表示质量。具体来说，他们使用具有一个隐藏层的 MLP 作为投影头 $g$。然后根据输出 <strong>$z_i &#x3D; g(h_i$)</strong> 和 <strong>$z_j &#x3D; g(h_j$)</strong> 计算对比损失。</p>\n<h1 id=\"SimCLR-Contrastive-Loss\"><a href=\"#SimCLR-Contrastive-Loss\" class=\"headerlink\" title=\"SimCLR: Contrastive Loss\"></a>SimCLR: Contrastive Loss</h1><p>一个小批量的 $N$ 个训练图像产生总共 $2N$ 个数据增强示例。对于每个positive pair $(i, j)$ 的增强示例，对比损失函数旨在最大化向量 $z_i$ 和 $z_j$ 的一致性。具体来说，损失是正则的温标缩放交叉熵损失（temperature-scaled cross entropy），旨在最大化 $z_i$ 和 $z_j$ 相对于批量中所有其他增强示例的一致性：<br>$$<br>l ; (i,j) &#x3D; -\\log \\frac{\\exp(;\\text{sim}(z_i, z_j) ;&#x2F; ;\\tau)}{\\sum_{k&#x3D;1}^{2N} \\mathbb{1}_{k \\neq i} \\exp(; \\text{sim}(z_i, z_k) ; &#x2F; ; \\tau)}<br>$$</p>\n<p>其中 $\\mathbb{1} \\in {0, 1}$ 是一个指示函数，如果 $k\\neq i$ 则输出 $1$，否则输出 $0$。$\\tau$ 是一个温度参数，它决定了指数增加的速度。</p>\n<p>$sim(z_i, z_j) &#x3D; \\frac{z_i \\cdot z_j}{|| z_i || || z_j ||}$ 是向量 $z_i$ 和 $z_j$ 之间的（标准化）点积。$z_i$ 和 $z_j$ 之间的相似度越高，点积越大，分子就越大。分母通过对 $z_i$ 和批次中的所有其他增强示例 $k$ 求和来标准化该值。归一化值的范围是$(0,1)$，其中接近 $1$ 的高分对应于正对$(i，j)$之间的高相似度以及 $i$ 与批次中的其他增强示例 $k$ 之间的低相似度。然后，负对数将范围$(0,1)$映射到损失值$(\\inf,0)$。</p>\n<p>总损失是针对批次中的所有正对$(i，j)$计算的。让 $z &#x3D; [z_1，z_2，…，z_{2N}]$ 包括批次中的所有增强示例，其中 $z_{1}…z_{N}$ 是左分支的输出，$z_{N+1}…z_{2N}$ 是右分支的输出。因此，对于 $\\forall k \\in [1，N]$，正对为$(z_{k}，z_{k + N})$。</p>\n<p>那么总损失$L$为：</p>\n<p>$$<br>L &#x3D; \\frac{1}{2N} \\sum_{k&#x3D;1}^{N} [; l(k,; k+N) + l(k+N,; k) ;]<br>$$</p>\n<p>关键代码实现如下:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sim</span>(<span class=\"params\">z_i, z_j</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Normalized dot product between two vectors.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Inputs:</span></span><br><span class=\"line\"><span class=\"string\">    - z_i: 1xD tensor.</span></span><br><span class=\"line\"><span class=\"string\">    - z_j: 1xD tensor.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">    - A scalar value that is the normalized dot product between z_i and z_j.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    norm_dot_product = <span class=\"literal\">None</span></span><br><span class=\"line\">    norm_dot_product = torch.<span class=\"built_in\">sum</span>(z_i * z_j) / (</span><br><span class=\"line\">                        (torch.sqrt(torch.<span class=\"built_in\">sum</span>(z_i ** <span class=\"number\">2</span>)) * torch.sqr(torch.<span class=\"built_in\">sum</span>(z_j ** <span class=\"number\">2</span>)) ))    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> norm_dot_product</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">simclr_loss_vectorized</span>(<span class=\"params\">out_left, out_right, tau, device=<span class=\"string\">&#x27;cuda&#x27;</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Compute the contrastive loss L over a batch (vectorized version). No loops are allowed.</span></span><br><span class=\"line\"><span class=\"string\">    </span></span><br><span class=\"line\"><span class=\"string\">    Inputs and output are the same as in simclr_loss_naive.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    N = out_left.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Concatenate out_left and out_right into a 2*N x D tensor.</span></span><br><span class=\"line\">    out = torch.cat([out_left, out_right], dim=<span class=\"number\">0</span>)  <span class=\"comment\"># [2*N, D]</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Compute similarity matrix between all pairs of augmented examples in the batch.</span></span><br><span class=\"line\">    sim_matrix = compute_sim_matrix(out)  <span class=\"comment\"># [2*N, 2*N]</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    exponential = <span class=\"literal\">None</span></span><br><span class=\"line\">    exponential =torch.exp(sim_matrix / tau).to(device)        <span class=\"comment\"># (2N, 2N)</span></span><br><span class=\"line\">    <span class=\"comment\"># This binary mask zeros out terms where k=i.</span></span><br><span class=\"line\">    mask = (torch.ones_like(exponential, device=device) - torch.eye(<span class=\"number\">2</span> * N, device=device)).to(device).<span class=\"built_in\">bool</span>()</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># apply the binary mask.</span></span><br><span class=\"line\">    exponential = exponential.masked_select(mask).view(<span class=\"number\">2</span> * N, -<span class=\"number\">1</span>)   <span class=\"comment\"># [2*N, 2*N-1]</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    denom = <span class=\"literal\">None</span></span><br><span class=\"line\">    denom = torch.<span class=\"built_in\">sum</span>(exponential, dim=<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>, device=device)</span><br><span class=\"line\"></span><br><span class=\"line\">    sim_pos_pairs = sim_positive_pairs(out_left, out_right).repeat(<span class=\"number\">2</span>, <span class=\"number\">1</span>).to(device)  <span class=\"comment\"># (N, 1)</span></span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    numerator = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">    numerator = torch.exp(sim_pos_pairs / tau)</span><br><span class=\"line\"></span><br><span class=\"line\">    loss = torch.<span class=\"built_in\">sum</span>(torch.log(denom) - torch.log(numerator)) </span><br><span class=\"line\">    loss /= (<span class=\"number\">2</span> * N)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Finetune-a-Linear-Layer-for-Classification\"><a href=\"#Finetune-a-Linear-Layer-for-Classification\" class=\"headerlink\" title=\"Finetune a Linear Layer for Classification\"></a>Finetune a Linear Layer for Classification</h1><p>最后从SimCLR 模型中移除投影头，并添加一个线性层来微调一个简单的分类任务。线性层之前的所有层都被冻结，只有最后一个线性层中的权重被训练。</p>\n"}